{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:38:26.376827Z",
     "start_time": "2025-04-04T21:38:24.332165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "from collections import deque, namedtuple"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:38:56.331658Z",
     "start_time": "2025-04-04T21:38:56.326556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "  def __init__(self, state_size, action_size, seed = 42):\n",
    "      super(Network, self).__init__()\n",
    "      self.seed = torch.manual_seed(seed)\n",
    "      self.fc1 = nn.Linear(state_size, 64)\n",
    "      self.fc2 = nn.Linear(64, 64)\n",
    "      self.fc3 = nn.Linear(64, action_size)\n",
    "\n",
    "  def forward(self, state):\n",
    "        x = self.fc1(state)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        return self.fc3(x)"
   ],
   "id": "21218095afe89abd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:58:54.449425Z",
     "start_time": "2025-04-04T21:58:54.096303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make('LunarLander-v2')\n",
    "state_shape = env.observation_space.shape\n",
    "state_size = env.observation_space.shape[0]\n",
    "number_actions = env.action_space.n\n",
    "print('State shape: ', state_shape)\n",
    "print('State size: ', state_size)\n",
    "print('Number of actions: ', number_actions)"
   ],
   "id": "2813eabde92e3055",
   "outputs": [
    {
     "ename": "DependencyNotInstalled",
     "evalue": "Box2D is not installed, you can install it by run `pip install swig` followed by `pip install \"gymnasium[box2d]\"`",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/gymnasium/envs/box2d/bipedal_walker.py:15\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 15\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mBox2D\u001B[39;00m\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mBox2D\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mb2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     17\u001B[0m         circleShape,\n\u001B[1;32m     18\u001B[0m         contactListener,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     22\u001B[0m         revoluteJointDef,\n\u001B[1;32m     23\u001B[0m     )\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'Box2D'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mDependencyNotInstalled\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgymnasium\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mgym\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m env \u001B[38;5;241m=\u001B[39m gym\u001B[38;5;241m.\u001B[39mmake(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLunarLander-v2\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m state_shape \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mobservation_space\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m      4\u001B[0m state_size \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mobservation_space\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/gymnasium/envs/registration.py:755\u001B[0m, in \u001B[0;36mmake\u001B[0;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001B[0m\n\u001B[1;32m    752\u001B[0m     env_creator \u001B[38;5;241m=\u001B[39m env_spec\u001B[38;5;241m.\u001B[39mentry_point\n\u001B[1;32m    753\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    754\u001B[0m     \u001B[38;5;66;03m# Assume it's a string\u001B[39;00m\n\u001B[0;32m--> 755\u001B[0m     env_creator \u001B[38;5;241m=\u001B[39m load_env_creator(env_spec\u001B[38;5;241m.\u001B[39mentry_point)\n\u001B[1;32m    757\u001B[0m \u001B[38;5;66;03m# Determine if to use the rendering\u001B[39;00m\n\u001B[1;32m    758\u001B[0m render_modes: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/gymnasium/envs/registration.py:553\u001B[0m, in \u001B[0;36mload_env_creator\u001B[0;34m(name)\u001B[0m\n\u001B[1;32m    544\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Loads an environment with name of style ``\"(import path):(environment name)\"`` and returns the environment creation function, normally the environment class type.\u001B[39;00m\n\u001B[1;32m    545\u001B[0m \n\u001B[1;32m    546\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    550\u001B[0m \u001B[38;5;124;03m    The environment constructor for the given environment name.\u001B[39;00m\n\u001B[1;32m    551\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    552\u001B[0m mod_name, attr_name \u001B[38;5;241m=\u001B[39m name\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 553\u001B[0m mod \u001B[38;5;241m=\u001B[39m importlib\u001B[38;5;241m.\u001B[39mimport_module(mod_name)\n\u001B[1;32m    554\u001B[0m fn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(mod, attr_name)\n\u001B[1;32m    555\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fn\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/importlib/__init__.py:90\u001B[0m, in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m     88\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m     89\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m---> 90\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _bootstrap\u001B[38;5;241m.\u001B[39m_gcd_import(name[level:], package, level)\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1387\u001B[0m, in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1360\u001B[0m, in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1310\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:488\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[0;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1387\u001B[0m, in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1360\u001B[0m, in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1331\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:935\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[0;34m(spec)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap_external>:995\u001B[0m, in \u001B[0;36mexec_module\u001B[0;34m(self, module)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:488\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[0;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/gymnasium/envs/box2d/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgymnasium\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01menvs\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbox2d\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbipedal_walker\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BipedalWalker, BipedalWalkerHardcore\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgymnasium\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01menvs\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbox2d\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcar_racing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CarRacing\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgymnasium\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01menvs\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbox2d\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlunar_lander\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LunarLander, LunarLanderContinuous\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/gymnasium/envs/box2d/bipedal_walker.py:25\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mBox2D\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mb2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     17\u001B[0m         circleShape,\n\u001B[1;32m     18\u001B[0m         contactListener,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     22\u001B[0m         revoluteJointDef,\n\u001B[1;32m     23\u001B[0m     )\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m---> 25\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m DependencyNotInstalled(\n\u001B[1;32m     26\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBox2D is not installed, run `pip install gymnasium[box2d]`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     27\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m TYPE_CHECKING:\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpygame\u001B[39;00m\n",
      "\u001B[0;31mDependencyNotInstalled\u001B[0m: Box2D is not installed, you can install it by run `pip install swig` followed by `pip install \"gymnasium[box2d]\"`"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:51:07.184152Z",
     "start_time": "2025-04-04T21:51:07.176998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "learning_rate = 5e-4\n",
    "minibatch_size = 100\n",
    "discount_factor = 0.99\n",
    "replay_buffer_size = int(1e5)\n",
    "interpolation_parameter = 1e-3learning_rate = 5e-4\n",
    "minibatch_size = 100\n",
    "discount_factor = 0.99\n",
    "replay_buffer_size = int(1e5)\n",
    "interpolation_parameter = 1e-3"
   ],
   "id": "e71b6e8b540be0bb",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (1695254556.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[9], line 5\u001B[0;36m\u001B[0m\n\u001B[0;31m    interpolation_parameter = 1e-3learning_rate = 5e-4\u001B[0m\n\u001B[0m                                 ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid decimal literal\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:51:22.909800Z",
     "start_time": "2025-04-04T21:51:22.901575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ReplayMemory(object):\n",
    "\n",
    "  def __init__(self, capacity):\n",
    "    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    self.capacity = capacity\n",
    "    self.memory = []\n",
    "\n",
    "  def push(self, event):\n",
    "    self.memory.append(event)\n",
    "    if len(self.memory) > self.capacity:\n",
    "      del self.memory[0]\n",
    "\n",
    "  def sample(self, batch_size):\n",
    "    experiences = random.sample(self.memory, k = batch_size)\n",
    "    states = torch.from_numpy(np.vstack([e[0] for e in experiences if e is not None])).float().to(self.device)\n",
    "    actions = torch.from_numpy(np.vstack([e[1] for e in experiences if e is not None])).long().to(self.device)\n",
    "    rewards = torch.from_numpy(np.vstack([e[2] for e in experiences if e is not None])).float().to(self.device)\n",
    "    next_states = torch.from_numpy(np.vstack([e[3] for e in experiences if e is not None])).float().to(self.device)\n",
    "    dones = torch.from_numpy(np.vstack([e[4] for e in experiences if e is not None]).astype(np.uint8)).float().to(self.device)\n",
    "    return states, next_states, actions, rewards, dones"
   ],
   "id": "14b1a3f4b2f8b1df",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:51:32.534687Z",
     "start_time": "2025-04-04T21:51:32.525516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Agent():\n",
    "\n",
    "  def __init__(self, state_size, action_size):\n",
    "    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    self.state_size = state_size\n",
    "    self.action_size = action_size\n",
    "    self.local_qnetwork = Network(state_size, action_size).to(self.device)\n",
    "    self.target_qnetwork = Network(state_size, action_size).to(self.device)\n",
    "    self.optimizer = optim.Adam(self.local_qnetwork.parameters(), lr = learning_rate)\n",
    "    self.memory = ReplayMemory(replay_buffer_size)\n",
    "    self.t_step = 0\n",
    "\n",
    "  def step(self, state, action, reward, next_state, done):\n",
    "    self.memory.push((state, action, reward, next_state, done))\n",
    "    self.t_step = (self.t_step + 1) % 4\n",
    "    if self.t_step == 0:\n",
    "      if len(self.memory.memory) > minibatch_size:\n",
    "        experiences = self.memory.sample(100)\n",
    "        self.learn(experiences, discount_factor)\n",
    "\n",
    "  def act(self, state, epsilon = 0.):\n",
    "    state = torch.from_numpy(state).float().unsqueeze(0).to(self.device)\n",
    "    self.local_qnetwork.eval()\n",
    "    with torch.no_grad():\n",
    "      action_values = self.local_qnetwork(state)\n",
    "    self.local_qnetwork.train()\n",
    "    if random.random() > epsilon:\n",
    "      return np.argmax(action_values.cpu().data.numpy())\n",
    "    else:\n",
    "      return random.choice(np.arange(self.action_size))\n",
    "\n",
    "  def learn(self, experiences, discount_factor):\n",
    "    states, next_states, actions, rewards, dones = experiences\n",
    "    next_q_targets = self.target_qnetwork(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "    q_targets = rewards + discount_factor * next_q_targets * (1 - dones)\n",
    "    q_expected = self.local_qnetwork(states).gather(1, actions)\n",
    "    loss = F.mse_loss(q_expected, q_targets)\n",
    "    self.optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    self.optimizer.step()\n",
    "    self.soft_update(self.local_qnetwork, self.target_qnetwork, interpolation_parameter)\n",
    "\n",
    "  def soft_update(self, local_model, target_model, interpolation_parameter):\n",
    "    for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "      target_param.data.copy_(interpolation_parameter * local_param.data + (1.0 - interpolation_parameter) * target_param.data)"
   ],
   "id": "8efbbe82da588be0",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:51:41.819796Z",
     "start_time": "2025-04-04T21:51:41.796550Z"
    }
   },
   "cell_type": "code",
   "source": "agent = Agent(state_size, number_actions)",
   "id": "4879411ef83f2f7",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m agent \u001B[38;5;241m=\u001B[39m Agent(state_size, number_actions)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'state_size' is not defined"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:52:03.081590Z",
     "start_time": "2025-04-04T21:52:03.039480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "number_episodes = 2000\n",
    "maximum_number_timesteps_per_episode = 1000\n",
    "epsilon_starting_value  = 1.0\n",
    "epsilon_ending_value  = 0.01\n",
    "epsilon_decay_value  = 0.995\n",
    "epsilon = epsilon_starting_value\n",
    "scores_on_100_episodes = deque(maxlen = 100)\n",
    "\n",
    "for episode in range(1, number_episodes + 1):\n",
    "  state, _ = env.reset()\n",
    "  score = 0\n",
    "  for t in range(maximum_number_timesteps_per_episode):\n",
    "    action = agent.act(state, epsilon)\n",
    "    next_state, reward, done, _, _ = env.step(action)\n",
    "    agent.step(state, action, reward, next_state, done)\n",
    "    state = next_state\n",
    "    score += reward\n",
    "    if done:\n",
    "      break\n",
    "  scores_on_100_episodes.append(score)\n",
    "  epsilon = max(epsilon_ending_value, epsilon_decay_value * epsilon)\n",
    "  print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores_on_100_episodes)), end = \"\")\n",
    "  if episode % 100 == 0:\n",
    "    print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores_on_100_episodes)))\n",
    "  if np.mean(scores_on_100_episodes) >= 200.0:\n",
    "    print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(episode - 100, np.mean(scores_on_100_episodes)))\n",
    "    torch.save(agent.local_qnetwork.state_dict(), 'checkpoint.pth')\n",
    "    break"
   ],
   "id": "48521234ac8f8b78",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m scores_on_100_episodes \u001B[38;5;241m=\u001B[39m deque(maxlen \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m100\u001B[39m)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m episode \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, number_episodes \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m---> 10\u001B[0m   state, _ \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mreset()\n\u001B[1;32m     11\u001B[0m   score \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     12\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(maximum_number_timesteps_per_episode):\n",
      "\u001B[0;31mNameError\u001B[0m: name 'env' is not defined"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:53:25.570083Z",
     "start_time": "2025-04-04T21:53:25.516798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import glob\n",
    "import io\n",
    "import base64\n",
    "import imageio\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def show_video_of_model(agent, env_name):\n",
    "    env = gym.make(env_name, render_mode='rgb_array')\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    frames = []\n",
    "    while not done:\n",
    "        frame = env.render()\n",
    "        frames.append(frame)\n",
    "        action = agent.act(state)\n",
    "        state, reward, done, _, _ = env.step(action.item())\n",
    "    env.close()\n",
    "    imageio.mimsave('video.mp4', frames, fps=30)\n",
    "\n",
    "show_video_of_model(agent, 'LunarLander-v3')\n",
    "\n",
    "def show_video():\n",
    "    mp4list = glob.glob('*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        display(HTML(data='''<video alt=\"test\" autoplay\n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else:\n",
    "        print(\"Could not find video\")\n",
    "\n",
    "show_video()"
   ],
   "id": "27bb6007129e3c",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 20\u001B[0m\n\u001B[1;32m     17\u001B[0m     env\u001B[38;5;241m.\u001B[39mclose()\n\u001B[1;32m     18\u001B[0m     imageio\u001B[38;5;241m.\u001B[39mmimsave(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvideo.mp4\u001B[39m\u001B[38;5;124m'\u001B[39m, frames, fps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m)\n\u001B[0;32m---> 20\u001B[0m show_video_of_model(agent, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLunarLander-v3\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mshow_video\u001B[39m():\n\u001B[1;32m     23\u001B[0m     mp4list \u001B[38;5;241m=\u001B[39m glob\u001B[38;5;241m.\u001B[39mglob(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m*.mp4\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'agent' is not defined"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
